"""Playground for tracking objects."""

import argparse
import io
import os
import pickle

import cv2
import numpy as np
import PIL
from matplotlib import pyplot as plt
from tqdm import tqdm

from utils.colors import colormap
from utils.datasets import get_classes


def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps):
    """Convert from the class boxes/segms/keyps format generated by the testing
    code.

    Taken directly from the Detectron codebase
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, keyps, classes


def visualize_detections(image,
                         boxes,
                         classes,
                         dataset,
                         threshold=0.7,
                         box_alpha=0.7,
                         dpi=200):
    class_list = get_classes(dataset)

    fig = plt.figure(frameon=False)
    fig.set_size_inches(image.shape[1] / dpi, image.shape[0] / dpi)
    ax = plt.Axes(fig, [0., 0., 1., 1.])
    ax.axis('off')
    fig.add_axes(ax)
    ax.imshow(image)

    # Display in largest to smallest order to reduce occlusion
    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
    sorted_inds = np.argsort(-areas)

    colors = colormap()

    color_id = 0
    for i in sorted_inds:
        bbox = boxes[i, :4]
        score = boxes[i, -1]
        color = colors[color_id, 0:3] / 255.0
        if score < threshold:
            continue

        ax.text(
            bbox[0], bbox[1] - 2,
            class_list[classes[i]] + ' {:0.2f}'.format(score).lstrip('0'),
            fontsize=3,
            family='serif',
            bbox=dict(
                facecolor='g', alpha=0.4, pad=0, edgecolor='none'),
            color='white')

        ax.add_patch(
            plt.Rectangle(
                (bbox[0], bbox[1]),
                bbox[2] - bbox[0],
                bbox[3] - bbox[1],
                fill=False,
                edgecolor=color,
                linewidth=2,
                alpha=box_alpha))
        color_id = (color_id + 1) % len(colors)

    buf = io.BytesIO()
    fig.savefig(buf, format='png', dpi=dpi)
    plt.close('all')
    buf.seek(0)
    image = PIL.Image.open(buf)
    return image


def main():
    # Use first line of file docstring as description if it exists.
    parser = argparse.ArgumentParser(
        description=__doc__.split('\n')[0] if __doc__ else '',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--detectron-pickle', required=True)
    parser.add_argument('--images-dir', required=True)
    parser.add_argument('--output-dir', required=True)
    parser.add_argument('--extension', default='.png')
    parser.add_argument('--dataset', default='coco', choices=['coco'])

    args = parser.parse_args()

    with open(args.detectron_pickle, 'rb') as f:
        data = pickle.load(f)

    frames = sorted(data.keys(), key=lambda x: int(x))

    for image_name in tqdm(frames):
        image = cv2.imread(
            os.path.join(args.images_dir, image_name + args.extension))
        image = image[:, :, ::-1]  # BGR -> RGB
        image_data = data[image_name]
        boxes, _, _, classes = convert_from_cls_format(
            image_data['boxes'], image_data['segmentations'],
            image_data['keypoints'])
        new_image = visualize_detections(
            image, boxes, classes, dataset=args.dataset)
        new_image.save(
            os.path.join(args.output_dir, image_name + '.png'))


if __name__ == "__main__":
    main()
